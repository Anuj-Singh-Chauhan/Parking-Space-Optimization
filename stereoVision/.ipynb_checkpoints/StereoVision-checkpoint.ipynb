{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a0cc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbb604",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "while True:\n",
    "    \n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.1/capture?')\n",
    "    frame = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    img = cv2.imdecode(frame, -1)\n",
    "\n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.2/capture?')\n",
    "    frame2 = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    img2 = cv2.imdecode(frame2, -1)\n",
    "    \n",
    "    k = cv2.waitKey(5)\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('images/stereoLeft/imageL'+str(num)+ '.png', img)\n",
    "        cv2.imwrite('images/stereoRight/imageR'+str(num)+ '.png', img2)\n",
    "        print(\"images saved!\")\n",
    "        num+=1\n",
    "    \n",
    "    cv2.imshow('Img 1', img)\n",
    "    cv2.imshow('Img 2', img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61672b14",
   "metadata": {},
   "source": [
    "## Clibration Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44511bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "081bc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chessboardSize = (11,7)\n",
    "frameSize = (320, 240)\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e9928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0], 0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "objpoints = []\n",
    "imgpointsL = []\n",
    "imgpointsR = []\n",
    "\n",
    "# imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "# imagesRight = glob.glob('images/stereoRight/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d628b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/ANPR1/stereoVision/modify'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "27620a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('images/stereoLeft/Im_L_1.png')\n",
    "grayL = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "print(retL)\n",
    "cv.imshow(\"img\", img)\n",
    "cv.waitKey(2000)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8588e80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imagesLeft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/ANPR1/stereoVision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgLeft, imgRight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mimagesLeft\u001b[49m, imagesRight):\n\u001b[0;32m      4\u001b[0m     imgL \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(imgLeft)\n\u001b[0;32m      5\u001b[0m     imgR \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(imgRight)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imagesLeft' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir('D:/ANPR1/stereoVision')\n",
    "cnt = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    framesize = (imgL.shape[1], imgL.shape[0])\n",
    "#     cv.imshow('img left', imgL)\n",
    "#     cv.imshow('img right', imgR)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "    os.chdir(path) \n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "    \n",
    "    \n",
    "    #print(retL, retR)\n",
    "    \n",
    "    if retL and retR == True:\n",
    "        #print(\"hello\")\n",
    "        objpoints.append(objp)\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "        \n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "        \n",
    "        cv.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv.imwrite(str(cnt)+\"L.png\", imgL) \n",
    "        cv.imshow('img left', imgL)\n",
    "        cv.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv.imwrite(str(cnt)+\"R.png\", imgR) \n",
    "        cv.imshow('img right', imgR)\n",
    "        cv.waitKey(1000)\n",
    "        cnt = cnt + 1\n",
    "    \n",
    "    os.chdir('D:/ANPR1/stereoVision')\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c3cb0fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retL 0.6333132187802121\n",
      "retR 0.5594231728520511\n"
     ]
    }
   ],
   "source": [
    "## Calibration\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "print(\"retL\", retL)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "print(\"retR\", retR)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a565eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3819874357888047\n"
     ]
    }
   ],
   "source": [
    "#Stereo Vision Calibration\n",
    "\n",
    "flags = 0\n",
    "flags |= cv.CALIB_FIX_INTRINSIC\n",
    "\n",
    "criteria_stereo = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "print(retStereo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "45397d43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parameters!\n"
     ]
    }
   ],
   "source": [
    "# Stereo Rectification\n",
    "\n",
    "rectifyScale = 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R = cv.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv.CV_16SC2)\n",
    "stereoMapR = cv.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "\n",
    "cv_file = cv.FileStorage('stereoMap.xml', cv.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x', stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y', stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x', stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y', stereoMapR[1])\n",
    "cv_file.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "622a1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "imagesRight = glob.glob('images/stereoRight/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "da03d60c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/stereoLeft\\\\Im_L_1.png',\n",
       " 'images/stereoLeft\\\\Im_L_10.png',\n",
       " 'images/stereoLeft\\\\Im_L_11.png',\n",
       " 'images/stereoLeft\\\\Im_L_12.png',\n",
       " 'images/stereoLeft\\\\Im_L_13.png',\n",
       " 'images/stereoLeft\\\\Im_L_14.png',\n",
       " 'images/stereoLeft\\\\Im_L_15.png',\n",
       " 'images/stereoLeft\\\\Im_L_16.png',\n",
       " 'images/stereoLeft\\\\Im_L_17.png',\n",
       " 'images/stereoLeft\\\\Im_L_18.png',\n",
       " 'images/stereoLeft\\\\Im_L_19.png',\n",
       " 'images/stereoLeft\\\\Im_L_2.png',\n",
       " 'images/stereoLeft\\\\Im_L_20.png',\n",
       " 'images/stereoLeft\\\\Im_L_3.png',\n",
       " 'images/stereoLeft\\\\Im_L_4.png',\n",
       " 'images/stereoLeft\\\\Im_L_5.png',\n",
       " 'images/stereoLeft\\\\Im_L_6.png',\n",
       " 'images/stereoLeft\\\\Im_L_7.png',\n",
       " 'images/stereoLeft\\\\Im_L_8.png',\n",
       " 'images/stereoLeft\\\\Im_L_9.png']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f2f46033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/stereoRight\\\\Im_R_1.png',\n",
       " 'images/stereoRight\\\\Im_R_10.png',\n",
       " 'images/stereoRight\\\\Im_R_11.png',\n",
       " 'images/stereoRight\\\\Im_R_12.png',\n",
       " 'images/stereoRight\\\\Im_R_13.png',\n",
       " 'images/stereoRight\\\\Im_R_14.png',\n",
       " 'images/stereoRight\\\\Im_R_15.png',\n",
       " 'images/stereoRight\\\\Im_R_16.png',\n",
       " 'images/stereoRight\\\\Im_R_17.png',\n",
       " 'images/stereoRight\\\\Im_R_18.png',\n",
       " 'images/stereoRight\\\\Im_R_19.png',\n",
       " 'images/stereoRight\\\\Im_R_2.png',\n",
       " 'images/stereoRight\\\\Im_R_20.png',\n",
       " 'images/stereoRight\\\\Im_R_3.png',\n",
       " 'images/stereoRight\\\\Im_R_4.png',\n",
       " 'images/stereoRight\\\\Im_R_5.png',\n",
       " 'images/stereoRight\\\\Im_R_6.png',\n",
       " 'images/stereoRight\\\\Im_R_7.png',\n",
       " 'images/stereoRight\\\\Im_R_8.png',\n",
       " 'images/stereoRight\\\\Im_R_9.png']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71e083ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:/ANPR1/stereoVision')\n",
    "cnt = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    \n",
    "    imgR, imgL = calibration.undistortRectify(imgR, imgL)\n",
    "    os.chdir(path) \n",
    "    cv.imwrite(str(cnt)+\"L.png\", imgL)\n",
    "    cv.imwrite(str(cnt)+\"R.png\", imgR)\n",
    "    os.chdir('D:/ANPR1/stereoVision')\n",
    "    cnt = cnt+1\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63bbc4",
   "metadata": {},
   "source": [
    "## StereoVision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a09729f",
   "metadata": {},
   "source": [
    "### dimention calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b1646a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512d1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed58ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANPR1\\anprsys1\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import triangulation as tri\n",
    "import calibration\n",
    "import urllib.request\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb9b3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89cf4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2b2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 120\n",
    "B = 3.5 #distance between the cameras in cm\n",
    "f = 4.8 #camera focal length mm\n",
    "alpha = 65\n",
    "pt1 = torch.empty(0, 4, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25ebb133",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 170.5ms\n",
      "Speed: 6.8ms preprocess, 170.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 180.8ms\n",
      "Speed: 4.1ms preprocess, 180.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 179.0ms\n",
      "Speed: 17.4ms preprocess, 179.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 173.4ms\n",
      "Speed: 3.0ms preprocess, 173.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 163.1ms\n",
      "Speed: 15.6ms preprocess, 163.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 169.0ms\n",
      "Speed: 4.0ms preprocess, 169.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 161.6ms\n",
      "Speed: 0.0ms preprocess, 161.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 151.2ms\n",
      "Speed: 3.0ms preprocess, 151.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 156.0ms\n",
      "Speed: 3.5ms preprocess, 156.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 158.5ms\n",
      "Speed: 3.0ms preprocess, 158.5ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 159.5ms\n",
      "Speed: 12.4ms preprocess, 159.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 176.0ms\n",
      "Speed: 3.0ms preprocess, 176.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 136.7ms\n",
      "Speed: 0.0ms preprocess, 136.7ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 180.8ms\n",
      "Speed: 0.0ms preprocess, 180.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 163.1ms\n",
      "Speed: 5.4ms preprocess, 163.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 145.8ms\n",
      "Speed: 3.5ms preprocess, 145.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 165.2ms\n",
      "Speed: 12.9ms preprocess, 165.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 170.0ms\n",
      "Speed: 3.0ms preprocess, 170.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 173.0ms\n",
      "Speed: 11.7ms preprocess, 173.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 161.1ms\n",
      "Speed: 3.4ms preprocess, 161.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 159.5ms\n",
      "Speed: 13.0ms preprocess, 159.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 165.4ms\n",
      "Speed: 3.0ms preprocess, 165.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 170.5ms\n",
      "Speed: 0.0ms preprocess, 170.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 172.4ms\n",
      "Speed: 3.0ms preprocess, 172.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 176.3ms\n",
      "Speed: 3.5ms preprocess, 176.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 174.5ms\n",
      "Speed: 8.4ms preprocess, 174.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 169.9ms\n",
      "Speed: 3.0ms preprocess, 169.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 152.8ms\n",
      "Speed: 15.6ms preprocess, 152.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 150.3ms\n",
      "Speed: 3.0ms preprocess, 150.3ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 156.7ms\n",
      "Speed: 4.0ms preprocess, 156.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 170.1ms\n",
      "Speed: 14.3ms preprocess, 170.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 154.2ms\n",
      "Speed: 3.0ms preprocess, 154.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 176.9ms\n",
      "Speed: 12.6ms preprocess, 176.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 171.0ms\n",
      "Speed: 4.0ms preprocess, 171.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 166.1ms\n",
      "Speed: 0.0ms preprocess, 166.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 165.3ms\n",
      "Speed: 3.0ms preprocess, 165.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 149.7ms\n",
      "Speed: 13.0ms preprocess, 149.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 167.8ms\n",
      "Speed: 3.0ms preprocess, 167.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 169.2ms\n",
      "Speed: 0.0ms preprocess, 169.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 161.8ms\n",
      "Speed: 3.6ms preprocess, 161.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 177.9ms\n",
      "Speed: 3.8ms preprocess, 177.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 177.9ms\n",
      "Speed: 0.0ms preprocess, 177.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 181.1ms\n",
      "Speed: 3.0ms preprocess, 181.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 167.2ms\n",
      "Speed: 0.0ms preprocess, 167.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 149.6ms\n",
      "Speed: 3.0ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 162.9ms\n",
      "Speed: 0.0ms preprocess, 162.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 160.1ms\n",
      "Speed: 2.9ms preprocess, 160.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 174.2ms\n",
      "Speed: 11.6ms preprocess, 174.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 172.7ms\n",
      "Speed: 3.0ms preprocess, 172.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 157.7ms\n",
      "Speed: 0.0ms preprocess, 157.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 150.5ms\n",
      "Speed: 3.0ms preprocess, 150.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 174.1ms\n",
      "Speed: 3.0ms preprocess, 174.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 145.2ms\n",
      "Speed: 0.0ms preprocess, 145.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 145.4ms\n",
      "Speed: 3.8ms preprocess, 145.4ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 158.3ms\n",
      "Speed: 3.0ms preprocess, 158.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 161.6ms\n",
      "Speed: 3.5ms preprocess, 161.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 163.6ms\n",
      "Speed: 3.0ms preprocess, 163.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 163.5ms\n",
      "Speed: 3.1ms preprocess, 163.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 174.2ms\n",
      "Speed: 0.0ms preprocess, 174.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 170.2ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 4.0ms preprocess, 170.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 165.2ms\n",
      "Speed: 3.0ms preprocess, 165.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 167.4ms\n",
      "Speed: 0.0ms preprocess, 167.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 150.4ms\n",
      "Speed: 4.3ms preprocess, 150.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 172.7ms\n",
      "Speed: 3.0ms preprocess, 172.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 171.6ms\n",
      "Speed: 0.0ms preprocess, 171.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 152.4ms\n",
      "Speed: 3.9ms preprocess, 152.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 160.2ms\n",
      "Speed: 2.0ms preprocess, 160.2ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 165.3ms\n",
      "Speed: 5.9ms preprocess, 165.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 166.7ms\n",
      "Speed: 3.0ms preprocess, 166.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 163.5ms\n",
      "Speed: 0.0ms preprocess, 163.5ms inference, 15.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 174.4ms\n",
      "Speed: 4.0ms preprocess, 174.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 155.8ms\n",
      "Speed: 14.3ms preprocess, 155.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 169.2ms\n",
      "Speed: 3.0ms preprocess, 169.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 170.0ms\n",
      "Speed: 15.6ms preprocess, 170.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 171.9ms\n",
      "Speed: 3.0ms preprocess, 171.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 148.2ms\n",
      "Speed: 18.7ms preprocess, 148.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 165.1ms\n",
      "Speed: 3.1ms preprocess, 165.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 181.0ms\n",
      "Speed: 0.0ms preprocess, 181.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 138.0ms\n",
      "Speed: 3.0ms preprocess, 138.0ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 170.6ms\n",
      "Speed: 0.0ms preprocess, 170.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 154.2ms\n",
      "Speed: 3.0ms preprocess, 154.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 174.2ms\n",
      "Speed: 2.1ms preprocess, 174.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 168.3ms\n",
      "Speed: 3.0ms preprocess, 168.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 173.7ms\n",
      "Speed: 0.0ms preprocess, 173.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 167.5ms\n",
      "Speed: 2.5ms preprocess, 167.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 153.8ms\n",
      "Speed: 15.6ms preprocess, 153.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 154.8ms\n",
      "Speed: 3.1ms preprocess, 154.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[28.037397577379295, 27.751398020715488, 26.692901208667095, 19.2443500940222, 18.4808680706517, 19.379062189010792, 17.773805482455415, 18.886938391220134, 18.27792684664976]\n",
      "[[8.133161306600122, 5.92566618715455, 14], [7.822181332916998, 6.159401717127736, 14], [7.12311207668835, 6.410571245017096, 14], [8.15854196441741, 6.71020467641588, 15], [7.83680853367484, 6.356703319265629, 14], [8.330850830008767, 6.411971415717079, 15], [7.694882727863797, 5.84973029554292, 14], [7.928211167863795, 6.338170475874366, 14], [7.615775134037782, 6.16334432389921, 14]]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "while True:\n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.1/capture?')\n",
    "    frame = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    frame_left = cv2.imdecode(frame, -1)\n",
    "    print(frame_left.shape)\n",
    "    recFrame = frame_left\n",
    "\n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.2/capture?')\n",
    "    frame2 = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    frame_right = cv2.imdecode(frame2, -1)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        frame_right, frame_left = calibration.undistortRectify(frame_right, frame_left)\n",
    "        \n",
    "        \n",
    "        frame_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "        frame_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        results_right = model(frame_right, classes = 2)\n",
    "        results_left = model(frame_left, classes = 2)\n",
    "        \n",
    "        \n",
    "        frame_right = cv2.cvtColor(frame_right, cv2.COLOR_RGB2BGR)\n",
    "        frame_left = cv2.cvtColor(frame_left, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        #calculating Depth change for yolo\n",
    "        center_right = 0\n",
    "        center_left = 0\n",
    "    \n",
    "        if np.shape(results_right[0].boxes.xyxy) != np.shape(pt1):\n",
    "            for result in results_right:\n",
    "                frame_right = result.plot()\n",
    "                h, w, c = frame_right.shape\n",
    "                boundBox = result.boxes[0].xyxy[0].numpy()    \n",
    "                center_point_right = ((boundBox[0] + boundBox[2]) / 2, (boundBox[1] + boundBox[3]) / 2)\n",
    "            \n",
    "                \n",
    "        if np.shape(results_left[0].boxes.xyxy) != np.shape(pt1):\n",
    "            for result in results_left:\n",
    "                frame_left = result.plot()\n",
    "                h, w, c = frame_left.shape\n",
    "                boundBox = result.boxes[0].xyxy[0].numpy()\n",
    "                center_point_left = ((boundBox[0] + boundBox[2]) / 2, (boundBox[1] + boundBox[3]) / 2)\n",
    "                \n",
    "        \n",
    "        if np.shape(results_right[0].boxes.xyxy) != np.shape(pt1) and np.shape(results_left[0].boxes.xyxy) != np.shape(pt1):\n",
    "            depth = tri.find_depth(center_point_right, center_point_left, frame_right, frame_left, B, f, alpha)\n",
    "            x.append(depth)\n",
    "        \n",
    "        #getting the length of the car\n",
    "        \n",
    "            lenResults = model(recFrame, classes = 2)\n",
    "        \n",
    "            lengthOfCarleft, rightlenOfCar = giveLen(recFrame, lenResults[0].boxes[0].xyxy[0].numpy(), alpha, depth)\n",
    "            y.append([lengthOfCarleft,rightlenOfCar, round(lengthOfCarleft+rightlenOfCar)])\n",
    "        \n",
    "\n",
    "    cv2.imshow(\"frame right\", frame_right)\n",
    "    cv2.imshow(\"frame left\", frame_left)\n",
    "        \n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "            \n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa5304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "frame_rate = 120\n",
    "B = 3.5 #distance between the cameras in cm\n",
    "f = 4.8 #camera focal length mm\n",
    "alpha = 65\n",
    "pt1 = torch.empty(0, 4, dtype=torch.int64)\n",
    "\n",
    "\n",
    "\n",
    "def giveLen(img, boundbox, angle, depth):\n",
    "    print(img.shape)\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    \n",
    "    ratio = angle/width;\n",
    "    \n",
    "    centerOfFrame = width/2\n",
    "    \n",
    "    leftpix = centerOfFrame - boundbox[0]\n",
    "    rightpix = boundbox[2] - centerOfFrame\n",
    "    \n",
    "#     print([boundbox[0], boundbox[1], centerOfFrame])\n",
    "    \n",
    "    leftang = ratio*leftpix\n",
    "    rightang = ratio*rightpix\n",
    "    \n",
    "    leftlen = math.tan((leftang * math.pi)/180)*depth\n",
    "    rightlen = math.tan((rightang * math.pi) / 180) * depth\n",
    "    \n",
    "#     if(boundbox[1] < centerOfFrame && boundbox[2] < centerOfFrame)\n",
    "    \n",
    "    return round(leftlen+rightlen)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def findCarLen():\n",
    "   \n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.1/capture?')\n",
    "    frame = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    frame_left = cv2.imdecode(frame, -1)\n",
    "    print(frame_left.shape)\n",
    "    recFrame = frame_left\n",
    "\n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.2/capture?')\n",
    "    frame2 = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    frame_right = cv2.imdecode(frame2, -1)\n",
    "        \n",
    "    frame_right, frame_left = calibration.undistortRectify(frame_right, frame_left)\n",
    "        \n",
    "                \n",
    "#     frame_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "#     frame_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "    results_right = model(frame_right, classes = 2)\n",
    "    results_left = model(frame_left, classes = 2)\n",
    "        \n",
    "        \n",
    "#     frame_right = cv2.cvtColor(frame_right, cv2.COLOR_RGB2BGR)\n",
    "#     frame_left = cv2.cvtColor(frame_left, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "    center_right = 0\n",
    "    center_left = 0\n",
    "    \n",
    "    if np.shape(results_right[0].boxes.xyxy) != np.shape(pt1):\n",
    "        for result in results_right:\n",
    "            frame_right = result.plot()\n",
    "            h, w, c = frame_right.shape\n",
    "            boundBox = result.boxes[0].xyxy[0].numpy()    \n",
    "            center_point_right = ((boundBox[0] + boundBox[2]) / 2, (boundBox[1] + boundBox[3]) / 2)\n",
    "            \n",
    "                \n",
    "    if np.shape(results_left[0].boxes.xyxy) != np.shape(pt1):\n",
    "        for result in results_left:\n",
    "            frame_left = result.plot()\n",
    "            h, w, c = frame_left.shape\n",
    "            boundBox = result.boxes[0].xyxy[0].numpy()\n",
    "            center_point_left = ((boundBox[0] + boundBox[2]) / 2, (boundBox[1] + boundBox[3]) / 2)\n",
    "                \n",
    "        \n",
    "    if np.shape(results_right[0].boxes.xyxy) != np.shape(pt1) and np.shape(results_left[0].boxes.xyxy) != np.shape(pt1):\n",
    "        depth = tri.find_depth(center_point_right, center_point_left, frame_right, frame_left, B, f, alpha)\n",
    "        x.append(depth)\n",
    "        \n",
    "        #getting the length of the car\n",
    "        \n",
    "        lenResults = model(recFrame, classes = 2)\n",
    "        \n",
    "        lengthOfCar = giveLen(recFrame, lenResults[0].boxes[0].xyxy[0].numpy(), alpha, depth)\n",
    "        y.append(lengthOfCar)\n",
    "        \n",
    "            \n",
    "        \n",
    "    cv2.imshow(\"frame right\", frame_right)\n",
    "    cv2.imshow(\"frame left\", frame_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66e903f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 174.4ms\n",
      "Speed: 0.0ms preprocess, 174.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 164.6ms\n",
      "Speed: 19.9ms preprocess, 164.6ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 167.1ms\n",
      "Speed: 0.0ms preprocess, 167.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 156.7ms\n",
      "Speed: 11.5ms preprocess, 156.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 147.1ms\n",
      "Speed: 0.0ms preprocess, 147.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 161.8ms\n",
      "Speed: 6.4ms preprocess, 161.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 139.4ms\n",
      "Speed: 15.4ms preprocess, 139.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 166.1ms\n",
      "Speed: 16.8ms preprocess, 166.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 164.4ms\n",
      "Speed: 0.0ms preprocess, 164.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 161.4ms\n",
      "Speed: 3.9ms preprocess, 161.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 161.6ms\n",
      "Speed: 0.0ms preprocess, 161.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 167.2ms\n",
      "Speed: 2.0ms preprocess, 167.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 160.1ms\n",
      "Speed: 15.7ms preprocess, 160.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 178.6ms\n",
      "Speed: 5.8ms preprocess, 178.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 153.5ms\n",
      "Speed: 3.0ms preprocess, 153.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 168.9ms\n",
      "Speed: 15.6ms preprocess, 168.9ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 166.1ms\n",
      "Speed: 3.2ms preprocess, 166.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 168.2ms\n",
      "Speed: 4.0ms preprocess, 168.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 170.1ms\n",
      "Speed: 15.8ms preprocess, 170.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 169.4ms\n",
      "Speed: 16.7ms preprocess, 169.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 164.8ms\n",
      "Speed: 4.0ms preprocess, 164.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 147.2ms\n",
      "Speed: 0.0ms preprocess, 147.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 171.7ms\n",
      "Speed: 11.4ms preprocess, 171.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 178.9ms\n",
      "Speed: 4.4ms preprocess, 178.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 178.6ms\n",
      "Speed: 0.0ms preprocess, 178.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 166.2ms\n",
      "Speed: 5.0ms preprocess, 166.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[19.931829753028637, 20.775280087902374, 19.91645606101925, 20.525029017082208]\n",
      "[14, 14, 14, 14]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "while True:\n",
    "    findCarLen()\n",
    "    \n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "            \n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466071c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [16.28791361942623, 17.561241379995952, 17.49991094160133, 17.526137169270154, 16.99294159617705, 17.47951039342574, 17.1777414711047]\n",
    "y = [9, 10, 9, 9, 9, 9, 9]\n",
    "\n",
    "xprev = [15.640397166726096,\n",
    "  17.338820765847164,\n",
    "  18.409136813314234,\n",
    "  16.554877339293125,\n",
    "  17.04151355414844,\n",
    "  18.165668213139345,\n",
    "  18.077425613947447,\n",
    "  17.8410764378197,\n",
    "  18.63346725312319,\n",
    "  18.56319836855977,\n",
    "  19.053300701174837,\n",
    "  17.389542686036172,\n",
    "  20.10393734200952,\n",
    "  16.86653820239778,\n",
    "  16.751068487841028,\n",
    "  17.65239062265811,\n",
    "  18.96317319055281,\n",
    "  17.847560053927186,\n",
    "  17.136584038309486,\n",
    "  17.829646246481122,\n",
    "  17.73260558219239]\n",
    "yprev = [13,\n",
    "  14,\n",
    "  16,\n",
    "  14,\n",
    "  15,\n",
    "  16,\n",
    "  15,\n",
    "  15,\n",
    "  16,\n",
    "  16,\n",
    "  16,\n",
    "  15,\n",
    "  18,\n",
    "  15,\n",
    "  14,\n",
    "  16,\n",
    "  17,\n",
    "  16,\n",
    "  15,\n",
    "  16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "291a8e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([20.539947105985927,\n",
       "  19.914817416600314,\n",
       "  19.68421715820651,\n",
       "  21.490727798323174,\n",
       "  20.084893276646742,\n",
       "  18.704616314444923,\n",
       "  18.69959513327171,\n",
       "  19.815626461431854,\n",
       "  19.176248013528173,\n",
       "  15.01788266031835,\n",
       "  18.797116800579573,\n",
       "  27.072266380771783,\n",
       "  26.878972086893416,\n",
       "  25.6166798423292],\n",
       " [14, 14, 14, 15, 14, 14, 14, 15, 15, 13, 16, 13, 13])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62cd905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth of the vehicle:  17.526137169270154\n",
      "length of the vehicle:  9\n"
     ]
    }
   ],
   "source": [
    "print(\"depth of the vehicle: \", x[3])\n",
    "print(\"length of the vehicle: \", y[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea6c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chessboardSize = (8,6)\n",
    "frameSize = ( 240 , 320)\n",
    "\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "\n",
    "objpoints = [] \n",
    "imgpointsL = [] \n",
    "imgpointsR = [] \n",
    "\n",
    "\n",
    "imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "imagesRight = glob.glob('images/stereoRight/*.png')\n",
    "\n",
    "os.chdir('D:/ANPR1/stereoVision')\n",
    "cnt = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    \n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "#     frameSize = imgL.shape\n",
    "    \n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv.imshow('img left', imgL)\n",
    "        cv.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv.imshow('img right', imgR)\n",
    "        os.chdir(path) \n",
    "        cv.imwrite(str(cnt)+\"L.png\", imgL)\n",
    "        cv.imwrite(str(cnt)+\"R.png\", imgR)\n",
    "        os.chdir('D:/ANPR1/stereoVision')\n",
    "        cnt = cnt+1\n",
    "        \n",
    "        cv.waitKey(1000)\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf53f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameSize = (320, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac9424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parameters!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flags = 0\n",
    "flags |= cv.CALIB_FIX_INTRINSIC\n",
    "\n",
    "\n",
    "criteria_stereo= (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "\n",
    "\n",
    "rectifyScale= 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv.CV_16SC2)\n",
    "stereoMapR = cv.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "cv_file = cv.FileStorage('stereoMap.xml', cv.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f39875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Function for stereo vision and depth estimation\n",
    "import triangulation as tri\n",
    "import calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e70f91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "imagesRight = glob.glob('images/stereoRight/*.png')\n",
    "path = 'D:/ANPR1/stereoVision/modify'\n",
    "os.chdir('D:/ANPR1/stereoVision')\n",
    "cnt = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    \n",
    "    imgR, imgL = calibration.undistortRectify(imgR, imgL)\n",
    "    os.chdir(path) \n",
    "    cv.imwrite(str(cnt)+\"L.png\", imgL)\n",
    "    cv.imwrite(str(cnt)+\"R.png\", imgR)\n",
    "    os.chdir('D:/ANPR1/stereoVision')\n",
    "    cnt = cnt+1\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cd78a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anprsys1",
   "language": "python",
   "name": "anprsys1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
