{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a0cc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cbb604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n",
      "images saved!\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "while True:\n",
    "    \n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.1/capture?')\n",
    "    frame = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    img = cv2.imdecode(frame, -1)\n",
    "\n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.2/capture?')\n",
    "    frame2 = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    img2 = cv2.imdecode(frame2, -1)\n",
    "    \n",
    "    k = cv2.waitKey(5)\n",
    "    \n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv2.imwrite('images/stereoLeft/imageL'+str(num)+ '.png', img)\n",
    "        cv2.imwrite('images/stereoRight/imageR'+str(num)+ '.png', img2)\n",
    "        print(\"images saved!\")\n",
    "        num+=1\n",
    "    \n",
    "    cv2.imshow('Img 1', img)\n",
    "    cv2.imshow('Img 2', img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61672b14",
   "metadata": {},
   "source": [
    "## Clibration Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44511bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "081bc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chessboardSize = (11,7)\n",
    "frameSize = (320, 240)\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e9928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0], 0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "objpoints = []\n",
    "imgpointsL = []\n",
    "imgpointsR = []\n",
    "\n",
    "# imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "# imagesRight = glob.glob('images/stereoRight/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d628b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/ANPR1/stereoVision/modify'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "27620a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('images/stereoLeft/Im_L_1.png')\n",
    "grayL = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "print(retL)\n",
    "cv.imshow(\"img\", img)\n",
    "cv.waitKey(2000)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8588e80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imagesLeft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:/ANPR1/stereoVision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgLeft, imgRight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mimagesLeft\u001b[49m, imagesRight):\n\u001b[0;32m      4\u001b[0m     imgL \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(imgLeft)\n\u001b[0;32m      5\u001b[0m     imgR \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(imgRight)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imagesLeft' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir('D:/ANPR1/stereoVision')\n",
    "cnt = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    framesize = (imgL.shape[1], imgL.shape[0])\n",
    "#     cv.imshow('img left', imgL)\n",
    "#     cv.imshow('img right', imgR)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "    os.chdir(path) \n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "    \n",
    "    \n",
    "    #print(retL, retR)\n",
    "    \n",
    "    if retL and retR == True:\n",
    "        #print(\"hello\")\n",
    "        objpoints.append(objp)\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "        \n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "        \n",
    "        cv.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv.imwrite(str(cnt)+\"L.png\", imgL) \n",
    "        cv.imshow('img left', imgL)\n",
    "        cv.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv.imwrite(str(cnt)+\"R.png\", imgR) \n",
    "        cv.imshow('img right', imgR)\n",
    "        cv.waitKey(1000)\n",
    "        cnt = cnt + 1\n",
    "    \n",
    "    os.chdir('D:/ANPR1/stereoVision')\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c3cb0fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retL 0.6333132187802121\n",
      "retR 0.5594231728520511\n"
     ]
    }
   ],
   "source": [
    "## Calibration\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "print(\"retL\", retL)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "print(\"retR\", retR)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3a565eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3819874357888047\n"
     ]
    }
   ],
   "source": [
    "#Stereo Vision Calibration\n",
    "\n",
    "flags = 0\n",
    "flags |= cv.CALIB_FIX_INTRINSIC\n",
    "\n",
    "criteria_stereo = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "print(retStereo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "45397d43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parameters!\n"
     ]
    }
   ],
   "source": [
    "# Stereo Rectification\n",
    "\n",
    "rectifyScale = 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R = cv.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv.CV_16SC2)\n",
    "stereoMapR = cv.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "\n",
    "cv_file = cv.FileStorage('stereoMap.xml', cv.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x', stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y', stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x', stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y', stereoMapR[1])\n",
    "cv_file.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "622a1b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "imagesRight = glob.glob('images/stereoRight/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da03d60c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/stereoLeft\\\\Im_L_1.png',\n",
       " 'images/stereoLeft\\\\Im_L_10.png',\n",
       " 'images/stereoLeft\\\\Im_L_11.png',\n",
       " 'images/stereoLeft\\\\Im_L_12.png',\n",
       " 'images/stereoLeft\\\\Im_L_13.png',\n",
       " 'images/stereoLeft\\\\Im_L_14.png',\n",
       " 'images/stereoLeft\\\\Im_L_15.png',\n",
       " 'images/stereoLeft\\\\Im_L_16.png',\n",
       " 'images/stereoLeft\\\\Im_L_17.png',\n",
       " 'images/stereoLeft\\\\Im_L_18.png',\n",
       " 'images/stereoLeft\\\\Im_L_19.png',\n",
       " 'images/stereoLeft\\\\Im_L_2.png',\n",
       " 'images/stereoLeft\\\\Im_L_20.png',\n",
       " 'images/stereoLeft\\\\Im_L_3.png',\n",
       " 'images/stereoLeft\\\\Im_L_4.png',\n",
       " 'images/stereoLeft\\\\Im_L_5.png',\n",
       " 'images/stereoLeft\\\\Im_L_6.png',\n",
       " 'images/stereoLeft\\\\Im_L_7.png',\n",
       " 'images/stereoLeft\\\\Im_L_8.png',\n",
       " 'images/stereoLeft\\\\Im_L_9.png']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesLeft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f46033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['images/stereoRight\\\\Im_R_1.png',\n",
       " 'images/stereoRight\\\\Im_R_10.png',\n",
       " 'images/stereoRight\\\\Im_R_11.png',\n",
       " 'images/stereoRight\\\\Im_R_12.png',\n",
       " 'images/stereoRight\\\\Im_R_13.png',\n",
       " 'images/stereoRight\\\\Im_R_14.png',\n",
       " 'images/stereoRight\\\\Im_R_15.png',\n",
       " 'images/stereoRight\\\\Im_R_16.png',\n",
       " 'images/stereoRight\\\\Im_R_17.png',\n",
       " 'images/stereoRight\\\\Im_R_18.png',\n",
       " 'images/stereoRight\\\\Im_R_19.png',\n",
       " 'images/stereoRight\\\\Im_R_2.png',\n",
       " 'images/stereoRight\\\\Im_R_20.png',\n",
       " 'images/stereoRight\\\\Im_R_3.png',\n",
       " 'images/stereoRight\\\\Im_R_4.png',\n",
       " 'images/stereoRight\\\\Im_R_5.png',\n",
       " 'images/stereoRight\\\\Im_R_6.png',\n",
       " 'images/stereoRight\\\\Im_R_7.png',\n",
       " 'images/stereoRight\\\\Im_R_8.png',\n",
       " 'images/stereoRight\\\\Im_R_9.png']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagesRight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71e083ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n",
      "(576, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('D:/ANPR1/stereoVision')\n",
    "cnt = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    print(imgL.shape)\n",
    "#     imgR, imgL = calibration.undistortRectify(imgR, imgL)\n",
    "#     os.chdir(path) \n",
    "#     cv.imwrite(str(cnt)+\"L.png\", imgL)\n",
    "#     cv.imwrite(str(cnt)+\"R.png\", imgR)\n",
    "#     os.chdir('D:/ANPR1/stereoVision')\n",
    "#     cnt = cnt+1\n",
    "\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63bbc4",
   "metadata": {},
   "source": [
    "## StereoVision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a09729f",
   "metadata": {},
   "source": [
    "### dimention calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b1646a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "512d1cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import imutils\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed58ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANPR1\\anprsys1\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import triangulation as tri\n",
    "import calibration\n",
    "import urllib.request\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb9b3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89cf4d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2b2fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 120\n",
    "B = 3.5 #distance between the cameras in cm\n",
    "f = 4.8 #camera focal length mm\n",
    "alpha = 65\n",
    "pt1 = torch.empty(0, 4, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ebb133",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 224.4ms\n",
      "Speed: 5.1ms preprocess, 224.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 205.3ms\n",
      "Speed: 4.1ms preprocess, 205.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 227.9ms\n",
      "Speed: 1.4ms preprocess, 227.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 201.7ms\n",
      "Speed: 4.1ms preprocess, 201.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 183.9ms\n",
      "Speed: 3.0ms preprocess, 183.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 165.1ms\n",
      "Speed: 4.0ms preprocess, 165.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 188.0ms\n",
      "Speed: 15.6ms preprocess, 188.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 212.1ms\n",
      "Speed: 0.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 190.7ms\n",
      "Speed: 4.0ms preprocess, 190.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'giveLen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 59\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m#getting the length of the car\u001b[39;00m\n\u001b[0;32m     57\u001b[0m         lenResults \u001b[38;5;241m=\u001b[39m model(recFrame, classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m         lengthOfCarleft, rightlenOfCar \u001b[38;5;241m=\u001b[39m \u001b[43mgiveLen\u001b[49m(recFrame, lenResults[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mxyxy[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy(), alpha, depth)\n\u001b[0;32m     60\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend([lengthOfCarleft,rightlenOfCar, \u001b[38;5;28mround\u001b[39m(lengthOfCarleft\u001b[38;5;241m+\u001b[39mrightlenOfCar)])\n\u001b[0;32m     63\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe right\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame_right)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'giveLen' is not defined"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "while True:\n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.1/capture?')\n",
    "    frame = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    frame_left = cv2.imdecode(frame, -1)\n",
    "    print(frame_left.shape)\n",
    "    recFrame = frame_left\n",
    "\n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.2/capture?')\n",
    "    frame2 = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    frame_right = cv2.imdecode(frame2, -1)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        frame_right, frame_left = calibration.undistortRectify(frame_right, frame_left)\n",
    "        \n",
    "        \n",
    "        frame_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "        frame_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        results_right = model(frame_right, classes = 2)\n",
    "        results_left = model(frame_left, classes = 2)\n",
    "        \n",
    "        \n",
    "        frame_right = cv2.cvtColor(frame_right, cv2.COLOR_RGB2BGR)\n",
    "        frame_left = cv2.cvtColor(frame_left, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        #calculating Depth change for yolo\n",
    "        center_right = 0\n",
    "        center_left = 0\n",
    "    \n",
    "        if np.shape(results_right[0].boxes.xyxy) != np.shape(pt1):\n",
    "            for result in results_right:\n",
    "                frame_right = result.plot()\n",
    "                h, w, c = frame_right.shape\n",
    "                boundBox = result.boxes[0].xyxy[0].numpy()    \n",
    "                center_point_right = ((boundBox[0] + boundBox[2]) / 2, (boundBox[1] + boundBox[3]) / 2)\n",
    "            \n",
    "                \n",
    "        if np.shape(results_left[0].boxes.xyxy) != np.shape(pt1):\n",
    "            for result in results_left:\n",
    "                frame_left = result.plot()\n",
    "                h, w, c = frame_left.shape\n",
    "                boundBox = result.boxes[0].xyxy[0].numpy()\n",
    "                center_point_left = ((boundBox[0] + boundBox[2]) / 2, (boundBox[1] + boundBox[3]) / 2)\n",
    "                \n",
    "        \n",
    "        if np.shape(results_right[0].boxes.xyxy) != np.shape(pt1) and np.shape(results_left[0].boxes.xyxy) != np.shape(pt1):\n",
    "            depth = tri.find_depth(center_point_right, center_point_left, frame_right, frame_left, B, f, alpha)\n",
    "            x.append(depth)\n",
    "        \n",
    "        #getting the length of the car\n",
    "        \n",
    "            lenResults = model(recFrame, classes = 2)\n",
    "        \n",
    "            lengthOfCarleft, rightlenOfCar = giveLen(recFrame, lenResults[0].boxes[0].xyxy[0].numpy(), alpha, depth)\n",
    "            y.append([lengthOfCarleft,rightlenOfCar, round(lengthOfCarleft+rightlenOfCar)])\n",
    "        \n",
    "\n",
    "    cv2.imshow(\"frame right\", frame_right)\n",
    "    cv2.imshow(\"frame left\", frame_left)\n",
    "        \n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "            \n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa5304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "frame_rate = 120\n",
    "B = 3.5 #distance between the cameras in cm\n",
    "f = 4.8 #camera focal length mm\n",
    "alpha = 65\n",
    "pt1 = torch.empty(0, 4, dtype=torch.int64)\n",
    "\n",
    "\n",
    "\n",
    "def giveLen(img, boundbox, angle, depth):\n",
    "    print(img.shape)\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    \n",
    "    ratio = angle/width;\n",
    "    \n",
    "    centerOfFrame = width/2\n",
    "    \n",
    "    leftpix = centerOfFrame - boundbox[0]\n",
    "    rightpix = boundbox[2] - centerOfFrame\n",
    "    \n",
    "#     print([boundbox[0], boundbox[1], centerOfFrame])\n",
    "    \n",
    "    leftang = ratio*leftpix\n",
    "    rightang = ratio*rightpix\n",
    "    \n",
    "    leftlen = math.tan((leftang * math.pi)/180)*depth\n",
    "    rightlen = math.tan((rightang * math.pi) / 180) * depth\n",
    "    \n",
    "#     if(boundbox[1] < centerOfFrame && boundbox[2] < centerOfFrame)\n",
    "    \n",
    "    return round(leftlen+rightlen)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def findCarLen():\n",
    "   \n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.1/capture?')\n",
    "    frame = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    frame_left = cv2.imdecode(frame, -1)\n",
    "    print(frame_left.shape)\n",
    "    recFrame = frame_left\n",
    "\n",
    "    imgResponse = urllib.request.urlopen('http://192.168.4.2/capture?')\n",
    "    frame2 = np.array(bytearray(imgResponse.read()), dtype = np.uint8)\n",
    "    frame_right = cv2.imdecode(frame2, -1)\n",
    "        \n",
    "    frame_right, frame_left = calibration.undistortRectify(frame_right, frame_left)\n",
    "        \n",
    "                \n",
    "#     frame_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "#     frame_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "    results_right = model(frame_right, classes = 2)\n",
    "    results_left = model(frame_left, classes = 2)\n",
    "        \n",
    "        \n",
    "#     frame_right = cv2.cvtColor(frame_right, cv2.COLOR_RGB2BGR)\n",
    "#     frame_left = cv2.cvtColor(frame_left, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "    center_right = 0\n",
    "    center_left = 0\n",
    "    \n",
    "    if np.shape(results_right[0].boxes.xyxy) != np.shape(pt1):\n",
    "        for result in results_right:\n",
    "            frame_right = result.plot()\n",
    "            h, w, c = frame_right.shape\n",
    "            boundBox = result.boxes[0].xyxy[0].numpy()    \n",
    "            center_point_right = ((boundBox[0] + boundBox[2]) / 2, (boundBox[1] + boundBox[3]) / 2)\n",
    "            \n",
    "                \n",
    "    if np.shape(results_left[0].boxes.xyxy) != np.shape(pt1):\n",
    "        for result in results_left:\n",
    "            frame_left = result.plot()\n",
    "            h, w, c = frame_left.shape\n",
    "            boundBox = result.boxes[0].xyxy[0].numpy()\n",
    "            center_point_left = ((boundBox[0] + boundBox[2]) / 2, (boundBox[1] + boundBox[3]) / 2)\n",
    "                \n",
    "        \n",
    "    if np.shape(results_right[0].boxes.xyxy) != np.shape(pt1) and np.shape(results_left[0].boxes.xyxy) != np.shape(pt1):\n",
    "        depth = tri.find_depth(center_point_right, center_point_left, frame_right, frame_left, B, f, alpha)\n",
    "        x.append(depth)\n",
    "        \n",
    "        #getting the length of the car\n",
    "        \n",
    "        lenResults = model(recFrame, classes = 2)\n",
    "        \n",
    "        lengthOfCar = giveLen(recFrame, lenResults[0].boxes[0].xyxy[0].numpy(), alpha, depth)\n",
    "        y.append(lengthOfCar)\n",
    "        \n",
    "            \n",
    "        \n",
    "    cv2.imshow(\"frame right\", frame_right)\n",
    "    cv2.imshow(\"frame left\", frame_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66e903f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 179.9ms\n",
      "Speed: 3.0ms preprocess, 179.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 181.6ms\n",
      "Speed: 5.0ms preprocess, 181.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 (no detections), 194.6ms\n",
      "Speed: 0.0ms preprocess, 194.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 200.0ms\n",
      "Speed: 4.1ms preprocess, 200.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 185.3ms\n",
      "Speed: 4.0ms preprocess, 185.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 170.3ms\n",
      "Speed: 3.0ms preprocess, 170.3ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 179.0ms\n",
      "Speed: 4.0ms preprocess, 179.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 186.6ms\n",
      "Speed: 4.0ms preprocess, 186.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 174.1ms\n",
      "Speed: 11.1ms preprocess, 174.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 179.1ms\n",
      "Speed: 3.0ms preprocess, 179.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "(240, 320, 3)\n",
      "\n",
      "0: 480x640 1 car, 172.7ms\n",
      "Speed: 12.8ms preprocess, 172.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 184.2ms\n",
      "Speed: 4.0ms preprocess, 184.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 183.5ms\n",
      "Speed: 4.0ms preprocess, 183.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "(240, 320, 3)\n",
      "[27.93453324050752, 27.960076719704862, 28.64778279428883]\n",
      "[17, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "while True:\n",
    "    findCarLen()\n",
    "    \n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "            \n",
    "print(x)\n",
    "print(y)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "466071c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [16.28791361942623, 17.561241379995952, 17.49991094160133, 17.526137169270154, 16.99294159617705, 17.47951039342574, 17.1777414711047]\n",
    "y = [9, 10, 9, 9, 9, 9, 9]\n",
    "\n",
    "xprev = [15.640397166726096,\n",
    "  17.338820765847164,\n",
    "  18.409136813314234,\n",
    "  16.554877339293125,\n",
    "  17.04151355414844,\n",
    "  18.165668213139345,\n",
    "  18.077425613947447,\n",
    "  17.8410764378197,\n",
    "  18.63346725312319,\n",
    "  18.56319836855977,\n",
    "  19.053300701174837,\n",
    "  17.389542686036172,\n",
    "  20.10393734200952,\n",
    "  16.86653820239778,\n",
    "  16.751068487841028,\n",
    "  17.65239062265811,\n",
    "  18.96317319055281,\n",
    "  17.847560053927186,\n",
    "  17.136584038309486,\n",
    "  17.829646246481122,\n",
    "  17.73260558219239]\n",
    "yprev = [13,\n",
    "  14,\n",
    "  16,\n",
    "  14,\n",
    "  15,\n",
    "  16,\n",
    "  15,\n",
    "  15,\n",
    "  16,\n",
    "  16,\n",
    "  16,\n",
    "  15,\n",
    "  18,\n",
    "  15,\n",
    "  14,\n",
    "  16,\n",
    "  17,\n",
    "  16,\n",
    "  15,\n",
    "  16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871d2b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([22.28426107387413, 27.20833211159601], [12, 14])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62cd905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth of the vehicle:  17.526137169270154\n",
      "length of the vehicle:  9\n"
     ]
    }
   ],
   "source": [
    "print(\"depth of the vehicle: \", x[3])\n",
    "print(\"length of the vehicle: \", y[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf46a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chessboardSize = (8,6)\n",
    "frameSize = ( 240 , 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea6c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import os\n",
    "\n",
    "path = 'D:/ANPR1/stereoVision/modify'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chessboardSize = (11,7)\n",
    "frameSize = ( 1024, 576)\n",
    "\n",
    "\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "\n",
    "objpoints = [] \n",
    "imgpointsL = [] \n",
    "imgpointsR = [] \n",
    "\n",
    "\n",
    "imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "imagesRight = glob.glob('images/stereoRight/*.png')\n",
    "\n",
    "os.chdir('D:/ANPR1/stereoVision')\n",
    "cnt = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    \n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "#     frameSize = imgL.shape\n",
    "    \n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv.imshow('img left', imgL)\n",
    "        cv.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv.imshow('img right', imgR)\n",
    "        os.chdir(path) \n",
    "        cv.imwrite(str(cnt)+\"L.png\", imgL)\n",
    "        cv.imwrite(str(cnt)+\"R.png\", imgR)\n",
    "        os.chdir('D:/ANPR1/stereoVision')\n",
    "        cnt = cnt+1\n",
    "        \n",
    "        cv.waitKey(1000)\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf53f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameSize = (320, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ac9424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parameters!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flags = 0\n",
    "flags |= cv.CALIB_FIX_INTRINSIC\n",
    "\n",
    "\n",
    "criteria_stereo= (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "\n",
    "\n",
    "rectifyScale= 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv.CV_16SC2)\n",
    "stereoMapR = cv.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "cv_file = cv.FileStorage('stereoMap.xml', cv.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f39875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import imutils\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556369cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for stereo vision and depth estimation\n",
    "import triangulation as tri\n",
    "import calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e70f91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "imagesRight = glob.glob('images/stereoRight/*.png')\n",
    "path = 'D:/ANPR1/stereoVision/modify'\n",
    "os.chdir('D:/ANPR1/stereoVision')\n",
    "cnt = 0\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    \n",
    "    imgR, imgL = calibration.undistortRectify(imgR, imgL)\n",
    "    os.chdir(path) \n",
    "    cv.imwrite(str(cnt)+\"L.png\", imgL)\n",
    "    cv.imwrite(str(cnt)+\"R.png\", imgR)\n",
    "    os.chdir('D:/ANPR1/stereoVision')\n",
    "    cnt = cnt+1\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4cd78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parameters!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "################ FIND CHESSBOARD CORNERS - OBJECT POINTS AND IMAGE POINTS #############################\n",
    "\n",
    "chessboardSize = (11,7)\n",
    "frameSize = (1024, 576)\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((chessboardSize[0] * chessboardSize[1], 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessboardSize[0],0:chessboardSize[1]].T.reshape(-1,2)\n",
    "\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpointsL = [] # 2d points in image plane.\n",
    "imgpointsR = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "imagesRight = glob.glob('images/stereoRight/*.png')\n",
    "\n",
    "for imgLeft, imgRight in zip(imagesLeft, imagesRight):\n",
    "\n",
    "    imgL = cv.imread(imgLeft)\n",
    "    imgR = cv.imread(imgRight)\n",
    "    grayL = cv.cvtColor(imgL, cv.COLOR_BGR2GRAY)\n",
    "    grayR = cv.cvtColor(imgR, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, cornersL = cv.findChessboardCorners(grayL, chessboardSize, None)\n",
    "    retR, cornersR = cv.findChessboardCorners(grayR, chessboardSize, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv.cornerSubPix(grayL, cornersL, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv.cornerSubPix(grayR, cornersR, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv.drawChessboardCorners(imgL, chessboardSize, cornersL, retL)\n",
    "        cv.imshow('img left', imgL)\n",
    "        cv.drawChessboardCorners(imgR, chessboardSize, cornersR, retR)\n",
    "        cv.imshow('img right', imgR)\n",
    "        cv.waitKey(1000)\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############## CALIBRATION #######################################################\n",
    "\n",
    "retL, cameraMatrixL, distL, rvecsL, tvecsL = cv.calibrateCamera(objpoints, imgpointsL, frameSize, None, None)\n",
    "heightL, widthL, channelsL = imgL.shape\n",
    "newCameraMatrixL, roi_L = cv.getOptimalNewCameraMatrix(cameraMatrixL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "\n",
    "retR, cameraMatrixR, distR, rvecsR, tvecsR = cv.calibrateCamera(objpoints, imgpointsR, frameSize, None, None)\n",
    "heightR, widthR, channelsR = imgR.shape\n",
    "newCameraMatrixR, roi_R = cv.getOptimalNewCameraMatrix(cameraMatrixR, distR, (widthR, heightR), 1, (widthR, heightR))\n",
    "\n",
    "\n",
    "\n",
    "########## Stereo Vision Calibration #############################################\n",
    "\n",
    "flags = 0\n",
    "flags |= cv.CALIB_FIX_INTRINSIC\n",
    "# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.\n",
    "# Hence intrinsic parameters are the same \n",
    "\n",
    "criteria_stereo= (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retStereo, newCameraMatrixL, distL, newCameraMatrixR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], criteria_stereo, flags)\n",
    "\n",
    "#print(newCameraMatrixL)\n",
    "#print(newCameraMatrixR)\n",
    "\n",
    "########## Stereo Rectification #################################################\n",
    "\n",
    "rectifyScale= 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv.stereoRectify(newCameraMatrixL, distL, newCameraMatrixR, distR, grayL.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv.initUndistortRectifyMap(newCameraMatrixL, distL, rectL, projMatrixL, grayL.shape[::-1], cv.CV_16SC2)\n",
    "stereoMapR = cv.initUndistortRectifyMap(newCameraMatrixR, distR, rectR, projMatrixR, grayR.shape[::-1], cv.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "cv_file = cv.FileStorage('stereoMap.xml', cv.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4ae05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anprsys1",
   "language": "python",
   "name": "anprsys1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
